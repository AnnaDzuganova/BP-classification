{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image \n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "from sklearn.model_selection import train_test_split \n",
    "from tensorflow.keras import utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Flatten, BatchNormalization, GlobalAveragePooling2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read_file = pd.read_excel(r'C:\\Users\\anndz\\Desktop\\BP\\COVID.metadata.xlsx')\n",
    "#read_file.to_csv(r'C:\\Users\\anndz\\Desktop\\BP\\COVID.metadata.csv', index = None, header=True)\n",
    "#COVID = read_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predspracovanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ycat = []\n",
    "Ybin = []\n",
    "#labels = ['Normal', 'Lung_Opacity','Viral Pneumonia','Tuberculosis']\n",
    "labels = ['Normal', 'Lung_Opacity','Viral_Pneumonia','Tuberculosis','COVID']\n",
    "size = 256\n",
    "\n",
    "def get_data(folder, Ycat, Ybin):\n",
    "    x = 0\n",
    "    data = []\n",
    "    for label in labels: \n",
    "        path = os.path.join(folder, label)\n",
    "        for images in os.listdir(path):\n",
    "            img = cv2.imread(os.path.join(folder,label, images))[...,::-1]\n",
    "            img = cv2.resize(img, (size, size))\n",
    "            img = img.astype('float16')\n",
    "            img /= 255\n",
    "            data.append(img)\n",
    "            Ycat.append(label)\n",
    "            if label == 'COVID':\n",
    "                Ybin.append(1)\n",
    "            else:\n",
    "                Ybin.append(0)\n",
    "        x = x + 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdata = get_data('',Ycat, Ybin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Xdata[1], cmap='gray')\n",
    "print(Ycat[1],Ybin[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Ycat[2], Ybin[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xdata = Xdata.sample(n=len(Xdata), random_state=1242)\n",
    "#Ycat = Ycat.sample(n=len(Ycat), random_state=1242)\n",
    "random.seed(151)\n",
    "Xdata = random.sample(Xdata,3600)\n",
    "random.seed(151)\n",
    "Ycat=random.sample(Ycat,3600)\n",
    "random.seed(151)\n",
    "Ybin=random.sample(Ybin,3600)\n",
    "X = np.array(Xdata)\n",
    "Ycat = np.array(Ycat)\n",
    "Ybin = np.array(Ybin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Ybin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ycat = utils.to_categorical(labels,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xBin_train, xBin_test, yBin_train, yBin_test = train_test_split(X, Ybin, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(xBin_test),len(yBin_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_shape=(256,256,3), activation='relu')) # Add an input shape! (features,)\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(256,256,3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "adam = Adam()\n",
    "#model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy']\n",
    "#model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(xBin_train, yBin_train, epochs=5, batch_size=10, validation_data=(xBin_test, yBin_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# range of X (no. of epochs)\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# plot\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "# orange is for \"orange\"\n",
    "plt.plot(epochs, val_acc, 'orange', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "predictions = np.argmax(model.predict(xBin_test), 1)\n",
    "#predictions = model.predict(xBin_test)\n",
    "#predictions = predictions.reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xBin_test.shape, predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(yBin_test, predictions, target_names = ['Non-COVID (Class 0)','COVID (Class 1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix : \\n')\n",
    "print(confusion_matrix(yBin_test, predictions)) #(actual, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, x_test.shape,y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(256,256,3)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2))),\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam()\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=adam, metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = model.fit(x_train, y_train, epochs = 3,batch_size=128, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = f.history['accuracy']\n",
    "val_acc = f.history['val_accuracy']\n",
    "loss = f.history['loss']\n",
    "val_loss = f.history['val_loss']\n",
    "\n",
    "epochs_range = range(3)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "predicted = np.argmax(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={\n",
    "   0:'Normal',\n",
    "   1:'Lung_Opacity',\n",
    "   2:'Viral_Pneumonia',\n",
    "   3:'Tuberculosis',\n",
    "   4:'COVID',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pd.crosstab(y_test, predicted))\n",
    "print(pd.crosstab(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predicted))#,labels = labels, target_names = ['Normal', 'Lung_Opacity','Viral_Pneumonia','Tuberculosis','COVID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
